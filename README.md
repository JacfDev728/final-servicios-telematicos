# To Run application

## Start and SSH into Vagrant VM 

```
vagrant up
vagrant ssh servidorWeb
```

## Run the webApp

```
cd /home/vagrant/webapp
export FLASK_APP=run.py
/usr/local/bin/flask run --host=0.0.0.0
```
# üöÄ EXAMEN FINAL: SERVICIOS TELEM√ÅTICOS - PROYECTO CLOUDNOVA

Este repositorio contiene la configuraci√≥n y evidencias del despliegue seguro y la implementaci√≥n de observabilidad para la aplicaci√≥n web de CloudNova en AWS EC2, utilizando Docker, Prometheus y Grafana.

---

## 1. Estructura del Proyecto

* Contiene el `Dockerfile`, `docker-compose.yml`, `nginx.conf`, y los certificados SSL autofirmados (`app.crt`, `app.key`).
* Contiene `prometheus.yml`, `alert.rules.yml` y las definiciones de los dashboards de Grafana (archivos `.json`).
* Archivos de configuraci√≥n de servicios (`node-exporter.service`, etc.).
* Capturas de pantalla del despliegue (acceso HTTPS, Grafana).

---
### 1.2. Despliegue en la Nube (AWS EC2)

* [cite_start]Se lanz√≥ una instancia EC2 y se configur√≥ un **Security Group** para permitir tr√°fico SSH (22), HTTP (80), HTTPS (443) y Grafana (3000). [cite: 15]
* [cite_start]Se instal√≥ Docker y se ejecut√≥ la aplicaci√≥n usando Docker Compose[cite: 16].
---
### 1.3. Estado Final y Estrategia de Despliegue
La soluci√≥n implementada cumple con todos los requisitos del examen, superando el principal desaf√≠o de saturaci√≥n de recursos de la instancia t3.micro.

Validaci√≥n Funcional (Staging): Para garantizar la estabilidad de la validaci√≥n, se utiliz√≥ una estrategia de Estacionamiento (Staging), ejecutando la aplicaci√≥n (Partes I/II) y el Monitoreo (Partes III/IV) por separado, ya que la capacidad de la t3.micro no permite correr los seis servicios principales simult√°neamente de forma estable.

** IP P√∫blica de la EC2 (Lab Actual): 35.172.184.223
**IP Privada de la EC2 (Conexi√≥n de Monitoreo): 172.31.26.79

üéØ Parte I y II: Empaquetado y Despliegue en AWS EC2 (HTTPS y Funcionalidad)

El despliegue consisti√≥ en una arquitectura de 3 contenedores (Nginx, Flask App, MySQL DB) orquestados por Docker Compose.
| Requisito | Descripci√≥n y soluci√≥n | Archivo / Comando Clave |
| :--- | :--- | :--- |
| HTTPS y Redirecci√≥n | Nginx se configur√≥ como reverse proxy en el puerto 443 con certificados auto-firmados (en ssl/). Se implement√≥ una regla de redirecci√≥n para forzar HTTP (80) -> HTTPS (443). | nginx.conf |
| Conexi√≥n DB | Problema: La aplicaci√≥n Flask no encontraba la DB, devolviendo un error 500 (Can't connect to local server through socket...). Soluci√≥n 1: Se cambi√≥ el host de DB de 'localhost' al nombre del servicio Docker 'db'. Soluci√≥n 2 (Final): Se agreg√≥ expl√≠citamente el puerto :3306 en la cadena de conexi√≥n para forzar el protocolo TCP/IP y evitar que Python buscara el archivo de socket. | webapp/config.py |
| Inicializaci√≥n de Tablas | Problema: El script init.sql fallaba al inicio de MySQL, dejando la tabla users vac√≠a (Empty set). Soluci√≥n: Se forz√≥ la creaci√≥n manual de la tabla users para que la aplicaci√≥n Flask pudiera realizar el POST y db.session.commit(). | exec... < init.sql |
| Comando Final de Despliegue | Se utiliz√≥ docker compose (sintaxis moderna) para construir la imagen con la correcci√≥n de config.py y desplegar los servicios. | docker compose up --build -d  |

üéØ Parte III: Monitoreo con Prometheus y Node Exporter

Los servicios de monitoreo se instalaron y se ejecutaron directamente en el host EC2 como servicios de systemd para reducir la complejidad de la red Docker.

---
## 2. Archivos del Repositorio

| Directorio / Archivo | Descripci√≥n | a |
| :--- | :--- | :--- |
| Configuraci√≥n de Nginx y orquestaci√≥n. | Parte 1 y 2 | |
| `Dockerfile` | Instrucciones para construir la imagen. | |
| `docker-compose.yml` | Define el servicio `webapp` y mapea los puertos. | |
| `nginx.conf (docker)` | Configuraci√≥n de Nginx (SSL, redirecci√≥n 80->443). | |
| Configuraci√≥n de m√©tricas y visualizaci√≥n. | Parte 3 y 4 | |
| `prometheus.yml` | Configuraci√≥n de los jobs de Node Exporter y Prometheus. | |
| `alert.rules.yml` | Definici√≥n de alertas (ej. CPU > 80%). | 
| `dashboard_cpu_disk.json` | Exportaci√≥n del dashboard custom (CPU/Memoria/Disco). | |
| **`README.md`** | Este archivo, documentaci√≥n y conclusiones. | |
---

## 3. Conclusi√≥n T√©cnica (Respuesta a Preguntas)

### ‚Ä¢ ¬øQu√© aprendi√≥ al integrar Docker, AWS y Prometheus?

Aprend√≠ a construir un **ciclo de vida de despliegue inmutable**. Docker garantiza que el entorno de la aplicaci√≥n es id√©ntico tanto localmente como en la nube (AWS), eliminando la dependencia de la infraestructura subyacente. La integraci√≥n de Prometheus me ense√±√≥ la importancia de la **recolecci√≥n de m√©tricas** desde el inicio para garantizar la salud del servicio y planificar la capacidad.

### ‚Ä¢ ¬øQu√© fue lo m√°s desafiante y c√≥mo lo resolver√≠a en un entorno real?

Lo m√°s desafiante fue la gesti√≥n de la **configuraci√≥n de red y seguridad (SSL/TLS)** entre Docker, Nginx y las Reglas de Seguridad de AWS (Security Groups). En un entorno real, esto se resolver√≠a utilizando un **Load Balancer (ELB/ALB)** de AWS para manejar la terminaci√≥n SSL/TLS y delegar el tr√°fico seguro a los contenedores internos. Tambi√©n se usar√≠a **Terraform** para gestionar la infraestructura de AWS como c√≥digo (IaC), asegurando que las reglas de seguridad sean siempre correctas.

### ‚Ä¢ ¬øQu√© beneficio aporta la observabilidad en el ciclo DevOps?

La observabilidad (a trav√©s de Prometheus y Grafana) permite a los equipos **DevOps** pasar de la simple monitorizaci√≥n reactiva a un enfoque proactivo. Al centralizar m√©tricas, *logs* y *traces*, se reduce dr√°sticamente el **Tiempo Medio de Resoluci√≥n (MTTR)** de los incidentes. Permite a los desarrolladores y operadores entender r√°pidamente qu√© est√° fallando (el por qu√©) y no solo cu√°ndo fall√≥ (el qu√©), acelerando la entrega de valor de forma segura y fiable.

---

## 4. Evidencias de Despliegue
* https://www.notion.so/final-servicios-telematicos-2af686ab5be58022a6b1d0030f59d755?source=copy_link
