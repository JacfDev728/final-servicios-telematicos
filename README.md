# To Run application

## Start and SSH into Vagrant VM 

```
vagrant up
vagrant ssh servidorWeb
```

## Run the webApp

```
cd /home/vagrant/webapp
export FLASK_APP=run.py
/usr/local/bin/flask run --host=0.0.0.0
```
# üöÄ EXAMEN FINAL: SERVICIOS TELEM√ÅTICOS - PROYECTO CLOUDNOVA

Este repositorio contiene la configuraci√≥n y evidencias del despliegue seguro y la implementaci√≥n de observabilidad para la aplicaci√≥n web de CloudNova en AWS EC2, utilizando Docker, Prometheus y Grafana.

---

## 1. Estructura del Proyecto

* Contiene el `Dockerfile`, `docker-compose.yml`, `nginx.conf`, y los certificados SSL autofirmados (`app.crt`, `app.key`).
* Contiene `prometheus.yml`, `alert.rules.yml` y las definiciones de los dashboards de Grafana (archivos `.json`).
* Archivos de configuraci√≥n de servicios (`node-exporter.service`, etc.).
* Capturas de pantalla del despliegue (acceso HTTPS, Grafana).

---
### 1.2. Despliegue en la Nube (AWS EC2)

* [cite_start]Se lanz√≥ una instancia EC2 y se configur√≥ un **Security Group** para permitir tr√°fico SSH (22), HTTP (80), HTTPS (443) y Grafana (3000). [cite: 15]
* [cite_start]Se instal√≥ Docker y se ejecut√≥ la aplicaci√≥n usando Docker Compose[cite: 16].
---
### 1.3. Estado Final y Estrategia de Despliegue
La soluci√≥n implementada cumple con todos los requisitos del examen, superando el principal desaf√≠o de saturaci√≥n de recursos de la instancia t3.micro.

Validaci√≥n Funcional (Staging): Para garantizar la estabilidad de la validaci√≥n, se utiliz√≥ una estrategia de Estacionamiento (Staging), ejecutando la aplicaci√≥n (Partes I/II) y el Monitoreo (Partes III/IV) por separado, ya que la capacidad de la t3.micro no permite correr los seis servicios principales simult√°neamente de forma estable.

** IP P√∫blica de la EC2 (Lab Actual): 35.172.184.223
**IP Privada de la EC2 (Conexi√≥n de Monitoreo): 172.31.26.79

üéØ Parte I y II: Empaquetado y Despliegue en AWS EC2 (HTTPS y Funcionalidad)

El despliegue consisti√≥ en una arquitectura de 3 contenedores (Nginx, Flask App, MySQL DB) orquestados por Docker Compose.
| Requisito | Descripci√≥n y soluci√≥n | Archivo / Comando Clave |
| :--- | :--- | :--- |
| HTTPS y Redirecci√≥n | Nginx se configur√≥ como reverse proxy en el puerto 443 con certificados auto-firmados (en ssl/). Se implement√≥ una regla de redirecci√≥n para forzar HTTP (80) -> HTTPS (443). | nginx.conf |
| Conexi√≥n DB | Problema: La aplicaci√≥n Flask no encontraba la DB, devolviendo un error 500 (Can't connect to local server through socket...). Soluci√≥n 1: Se cambi√≥ el host de DB de 'localhost' al nombre del servicio Docker 'db'. Soluci√≥n 2 (Final): Se agreg√≥ expl√≠citamente el puerto :3306 en la cadena de conexi√≥n para forzar el protocolo TCP/IP y evitar que Python buscara el archivo de socket. | webapp/config.py |
| Inicializaci√≥n de Tablas | Problema: El script init.sql fallaba al inicio de MySQL, dejando la tabla users vac√≠a (Empty set). Soluci√≥n: Se forz√≥ la creaci√≥n manual de la tabla users para que la aplicaci√≥n Flask pudiera realizar el POST y db.session.commit(). | exec... < init.sql |
| Comando Final de Despliegue | Se utiliz√≥ docker compose (sintaxis moderna) para construir la imagen con la correcci√≥n de config.py y desplegar los servicios. | docker compose up --build -d  |

üéØ Parte III: Monitoreo con Prometheus y Node Exporter

Los servicios de monitoreo se instalaron y se ejecutaron directamente en el host EC2 como servicios de systemd para reducir la complejidad de la red Docker.
| Requisito | Descripci√≥n y soluci√≥n | Archivo / Comando Clave |
| :--- | :--- | :--- |
| Instalaci√≥n | Instalaci√≥n de binarios y configuraci√≥n de usuarios (prometheus, node_exporter). Se crearon los archivos .service y se habilitaron con sudo systemctl enable. | prometheus.service & node_exporter.service |
| Configuraci√≥n | Se configur√≥ prometheus.yml para recolectar m√©tricas del propio Prometheus y del Node Exporter en el host. | prometheus.yml (Targets: localhost:9090 y localhost:9100) |
| Validaci√≥n | Se verific√≥ que ambas metas est√©n en estado UP accediendo a la UI de Prometheus. | http://35.172.184.223:9090/targets |

üéØ Parte IV: Visualizaci√≥n con Grafana
| Requisito | Descripci√≥n y soluci√≥n | Archivo / Comando Clave |
| :--- | :--- | :--- |
| Instalaci√≥n | Grafana se despleg√≥ en un contenedor Docker separado. | docker run -d --name=grafana -p 3000:3000 grafana/grafana:latest |
| Conexi√≥n a Prometheus | Problema: Al usar localhost o 127.0.0.1, Grafana no pod√≠a ver a Prometheus (error connection refused). Soluci√≥n: Se configur√≥ la fuente de datos para apuntar a la IP privada del host EC2 para que el contenedor pueda acceder al servicio systemd en la red de AWS. | http://172.31.26.79:9090 |
| Dashboards | Se import√≥ el panel preconfigurado ID 1860 (Node Exporter Full) y se crearon paneles adicionales para validar el requisito. | Dashboards creados y ID 1860 importado. |
---
## 2. Archivos del Repositorio

| Directorio / Archivo | Descripci√≥n | a |
| :--- | :--- | :--- |
| Configuraci√≥n de Nginx y orquestaci√≥n. | Parte 1 y 2 | |
| `Dockerfile` | Instrucciones para construir la imagen. | |
| `docker-compose.yml` | Define el servicio `webapp` y mapea los puertos. | |
| `nginx.conf (docker)` | Configuraci√≥n de Nginx (SSL, redirecci√≥n 80->443). | |
| Configuraci√≥n de m√©tricas y visualizaci√≥n. | Parte 3 y 4 | |
| `prometheus.yml` | Configuraci√≥n de los jobs de Node Exporter y Prometheus. | |
| `alert.rules.yml` | Definici√≥n de alertas (ej. CPU > 80%). | 
| `dashboard_cpu_disk.json` | Exportaci√≥n del dashboard custom (CPU/Memoria/Disco). | |
| **`README.md`** | Este archivo, documentaci√≥n y conclusiones. | |
---

## 3. Conclusi√≥n T√©cnica (Respuesta a Preguntas)

### ‚Ä¢ ¬øQu√© aprendi√≥ al integrar Docker, AWS y Prometheus?

Aprend√≠ a crear un **Pipeline DevOps** modular donde **la portabilidad de Docker** y la **escalabilidad de AWS** se combinan con la observabilidad en tiempo real de Prometheus y Grafana. El principal aprendizaje fue que el dise√±o de la arquitectura (monitoreo como servicio sidecar en contenedores o como servicio de host) es fundamental para gestionar los recursos en entornos de infraestructura limitada.

### ‚Ä¢ ¬øQu√© fue lo m√°s desafiante y c√≥mo lo resolver√≠a en un entorno real?

El mayor desaf√≠o fue la **saturaci√≥n constante de la instancia t3.micro** al intentar correr la aplicaci√≥n web y el monitoreo juntos, lo que oblig√≥ a usar una estrategia de Estacionamiento (Staging). En un entorno real, esto se resuelve con un **dise√±o de microservicios distribuido**, donde Prometheus y Grafana correr√≠an en una **instancia separada** (o un servicio gestionado de AWS como ECS/EKS y CloudWatch) para aislar la carga y garantizar la estabilidad de la aplicaci√≥n cr√≠tica.

### ‚Ä¢ ¬øQu√© beneficio aporta la observabilidad en el ciclo DevOps?

La observabilidad, facilitada por Prometheus y Grafana, aporta el beneficio de la detecci√≥n proactiva de fallas y la **reducci√≥n del tiempo de resoluci√≥n (MTTR)**. Permite obtener m√©tricas en tiempo real sobre el rendimiento (CPU, RAM, latencia de la aplicaci√≥n), guiando las decisiones de **escalabilidad, optimizaci√≥n de c√≥digo y la validaci√≥n autom√°tica de nuevos despliegues**.

---

## 4. Evidencias de Despliegue
* https://www.notion.so/final-servicios-telematicos-2af686ab5be58022a6b1d0030f59d755?source=copy_link
